ðŸŽ§ Mood-Based Music Recommendation Web App

A full-stack web application that detects a userâ€™s mood through real-time facial analysis using MediaPipe Face Landmarker and recommends music accordingly.
The entire AI inference runs locally in the browser, ensuring user privacy.

ðŸš€ Features

ðŸŽ¥ Real-time face detection using webcam
ðŸ§  Mood detection based on facial blendshapes
ðŸŽ¶ Mood-based music recommendation
âš¡ Smooth, responsive UI with animations
ðŸ”’ Privacy-first (no face data sent to server)
ðŸ“± Fully responsive (desktop & mobile)

ðŸ›  Tech Stack
Frontend

React
Tailwind CSS
Framer Motion
MediaPipe Face Landmarker (WASM)
Axios

Backend
Node.js
Express
ImageKit (media storage)
REST APIs

ðŸ§  How Mood Detection Works

User allows camera access
MediaPipe detects facial landmarks
Facial blendshape values (smile, frown, brow movement) are extracted
Blendshapes are mapped to moods like:
Happy
Neutral
Sad
Angry
Mood is sent to backend API
Backend responds with mood-based song recommendations
All facial analysis runs entirely in the browser â€” no images or videos are stored or transmitted.

Project structure
frontend/
 â”œâ”€â”€ src/
 â”‚   â”œâ”€â”€ components/
 â”‚   â”œâ”€â”€ pages/
 â”‚   â”œâ”€â”€ context/
 â”‚   â”œâ”€â”€ hooks/
 â”‚   â”œâ”€â”€ utils/
 â”‚   â””â”€â”€ App.jsx

backend/
 â”œâ”€â”€ src/
 â”‚   â”œâ”€â”€ routes/
 â”‚   â”œâ”€â”€ services/
 â”‚   â”œâ”€â”€ db/
 â”‚   â””â”€â”€ app.js
 â””â”€â”€ server.js

